# üìú AI-Powered PDF Q&A System  
> **Ask AI questions about any PDF using RAG (Retrieval-Augmented Generation)**  

## üöÄ Features  
‚úÖ **Extracts and indexes PDF text**  
‚úÖ **Retrieves relevant chunks from stored PDFs**  
‚úÖ **Uses LLaMA 3.2 (via Ollama) for answering questions**  
‚úÖ **Fully local ‚Äì No API keys, No cloud required**  
‚úÖ **Simple CLI interface for now (Future Web UI planned)**  

---

## üõ† Installation & Setup  

### 1Ô∏è‚É£ Clone This Repository  
```bash
git clone https://github.com/chirag-bhardwaj/pdf-rag.git
cd pdf-rag
```

### 2Ô∏è‚É£ Create a Virtual Environment  
#### For macOS/Linux  
```bash
python -m venv venv
source venv/bin/activate
```
#### For Windows  
```bash
python -m venv venv
venv\Scripts\activate
```

### 3Ô∏è‚É£ Install Dependencies  
```bash
pip install -r requirements.txt
```

### 4Ô∏è‚É£ Install Ollama (for LLaMA 3.2 model)  
#### For macOS  
```bash
brew install ollama
```
#### For Linux  
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 5Ô∏è‚É£ Pull LLaMA 3.2 Model  
```bash
ollama pull llama3.2:latest
```

---

## üìå How to use  

### 1Ô∏è‚É£ Start the PDF Q&A System  
```bash
python pdf_qa.py
```

### 2Ô∏è‚É£ Upload a PDF  
- When prompted, **enter the path** to your PDF.  
- The system will **extract and index** the text from the PDF.

### 3Ô∏è‚É£ Ask Questions About the PDF  
- **Type any natural language question** (e.g., `What is this document about?`).  
- The system will **retrieve relevant content** and ask **LLaMA** for an answer.

---

## üõ† Requirements  
- **Python 3.10+**  
- **Ollama Installed** (for LLaMA 3.2)  
- **FAISS or ChromaDB** (for fast text retrieval)  
