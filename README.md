# üìú AI-Powered PDF Q&A System  
> **Ask AI questions about any PDF using RAG (Retrieval-Augmented Generation)**  

## üöÄ Features  
‚úÖ **Extracts and indexes PDF text**  
‚úÖ **Retrieves relevant chunks from stored PDFs**  
‚úÖ **Uses LLaMA 3.2 (via Ollama) for answering questions**  
‚úÖ **Fully local ‚Äì No API keys, No cloud required**  
‚úÖ **Simple CLI interface for now (Future Web UI planned)**  

---

## üõ† Installation & Setup  

```bash
# 1Ô∏è‚É£ Clone This Repository  
git clone https://github.com/YOUR_GITHUB_USERNAME/pdf-rag.git
cd pdf-rag

# 2Ô∏è‚É£ Create a Virtual Environment  
# For macOS/Linux  
python -m venv venv
source venv/bin/activate

# For Windows  
python -m venv venv
venv\Scripts\activate

# 3Ô∏è‚É£ Install Dependencies  
pip install -r requirements.txt

# 4Ô∏è‚É£ Install Ollama (for LLaMA 3.2 model)  
# For macOS  
brew install ollama

# For Linux  
curl -fsSL https://ollama.ai/install.sh | sh

# 5Ô∏è‚É£ Pull LLaMA 3.2 Model  
ollama pull llama3.2:latest
```

---

## üìå How to use

```bash
# 1Ô∏è‚É£ Start the PDF Q&A System  
python pdf_qa.py

# 2Ô∏è‚É£ Upload a PDF  
# When prompted, enter the path to your PDF.
# The system will extract and index the text from the PDF.

# 3Ô∏è‚É£ Ask Questions About the PDF  
# Type any natural language question (e.g., "What is this document about?").
# The system will retrieve relevant content and ask LLaMA for an answer.
```

---

## üõ† Requirements

# - Python 3.10+
# - Ollama Installed (for LLaMA 3.2)
# - FAISS or ChromaDB (for fast text retrieval)

